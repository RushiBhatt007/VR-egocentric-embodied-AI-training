{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datacollector.ipynb\n",
    "\n",
    "This notebook has two functions:\n",
    "- Generating training data (teleop control)\n",
    "- Running a trained model\n",
    "\n",
    "The first section of this notebook sets up the VR enviornment.  It must be run regardless of which of these tasks you'd like to do.\n",
    "\n",
    "# Core section (run this part if you want to do either task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet\n",
    "import time\n",
    "import pybullet_data\n",
    "import pybullet_robots\n",
    "import math\n",
    "import numpy as np\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup constants\n",
    "\n",
    "#width and height for rgb and depth image\n",
    "IMG_WIDTH = 160\n",
    "IMG_HEIGHT = 120\n",
    "\n",
    "#robot constants\n",
    "NUM_JOINTS = 6\n",
    "FINGER_AXES = [4, 6]\n",
    "\n",
    "#data record path\n",
    "DATA_PATH = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup global variables\n",
    "runNumber = 0 #folder number to save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using vr\n",
      "c:\\Users\\Ronak\\anaconda3\\envs\\torch\\lib\\site-packages\\pybullet_data\n"
     ]
    }
   ],
   "source": [
    "usingVR = True\n",
    "\n",
    "#setup the simulation\n",
    "if usingVR:\n",
    "    physics = pybullet.connect(pybullet.SHARED_MEMORY)\n",
    "    if (physics<0):\n",
    "        print('could not use vr!')\n",
    "    else:\n",
    "        print('using vr')\n",
    "else:\n",
    "    physics = pybullet.connect(pybullet.GUI)\n",
    "\n",
    "#add a plane to the simulation\n",
    "pybullet.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "print(pybullet_data.getDataPath())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For VR to work, you must compile bullet3 with VR support and run \"App_SharedMemoryPhysics_VR\" as described here: https://github.com/bulletphysics/bullet3\n",
    "\n",
    "After you compile this and launch the App_SharedMemoryPhysics_VR.exe file, the above cell should say \"using vr\" .  Make sure this output is produced before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomPos(x_range = [-0.6, -0.2], y_range = [-0.2, 0]):\n",
    "        x = np.random.uniform(x_range[0], x_range[1])\n",
    "        y = np.random.uniform(y_range[0], y_range[1])\n",
    "        return [x, y, 0.7]\n",
    "\n",
    "def reset():\n",
    "    # clear all the objects in the simulation\n",
    "    pybullet.resetSimulation()\n",
    "    plainId = pybullet.loadURDF(\"plane.urdf\", [0, 0, 0], useFixedBase=True)\n",
    "\n",
    "    # #add a table in front of the robot arm\n",
    "    tableId = pybullet.loadURDF(\"table/table.urdf\", basePosition=[0,0,0])\n",
    "\n",
    "    #add misc objects to the simulation on the table\n",
    "    pybullet.loadURDF(\"lego/lego.urdf\", basePosition=[-0.6,-0.2,0.7], globalScaling=2.5)\n",
    "\n",
    "    pybullet.loadURDF(\"tray/traybox.urdf\", basePosition=[0.1, -0.3, 0.65], globalScaling=0.5)\n",
    "\n",
    "    #add a robot arm to the simulation\n",
    "    robotId = pybullet.loadURDF(\"kuka_iiwa/model_vr_limits.urdf\", [-0,0.3,0.6], useFixedBase=True)\n",
    "    kuka_gripper_id = pybullet.loadSDF(\"gripper/wsg50_one_motor_gripper_new_free_base.sdf\")[0]\n",
    "    # attach gripper to kuka arm\n",
    "    kuka_cid = pybullet.createConstraint(robotId, 6, kuka_gripper_id, 0, pybullet.JOINT_FIXED, [0, 0, 0], [0, 0, 0.05], [0, 0, 0])\n",
    "    kuka_cid2 = pybullet.createConstraint(kuka_gripper_id, 4, kuka_gripper_id, 6, jointType=pybullet.JOINT_GEAR, jointAxis=[1,1,1], parentFramePosition=[0,0,0], childFramePosition=[0,0,0])\n",
    "    pybullet.changeConstraint(kuka_cid2, gearRatio=-1, erp=0.5, relativePositionTarget=0, maxForce=100)\n",
    "    # robotId = pybullet.loadURDF(\"kuka_iiwa/model.urdf\", [-0,0.3,0.6], useFixedBase=True)\n",
    "    #set the arm to an experimentally good starting position\n",
    "    # reset kuka\n",
    "    jointPositions = [-0.000000, -0.000000, 0.000000, 1.570793, 0.000000, -1.036725, 0.000001]\n",
    "    for jointIndex in range(pybullet.getNumJoints(robotId)):\n",
    "        pybullet.resetJointState(robotId, jointIndex, jointPositions[jointIndex])\n",
    "        pybullet.setJointMotorControl2(robotId, jointIndex, pybullet.POSITION_CONTROL, jointPositions[jointIndex], 0)\n",
    "\n",
    "    # reset gripper\n",
    "    pybullet.resetBasePositionAndOrientation(kuka_gripper_id, [0.923103, -0.200000, 1.250036], [-0.000000, 0.964531, -0.000002, -0.263970])\n",
    "    jointPositions = [0.000000, -0.011130, -0.206421, 0.205143, -0.009999, 0.000000, -0.010055, 0.000000]\n",
    "    for jointIndex in range(pybullet.getNumJoints(kuka_gripper_id)):\n",
    "        pybullet.resetJointState(kuka_gripper_id, jointIndex, jointPositions[jointIndex])\n",
    "        pybullet.setJointMotorControl2(kuka_gripper_id, jointIndex, pybullet.POSITION_CONTROL, jointPositions[jointIndex], 0)\n",
    "\n",
    "    num_joints = pybullet.getNumJoints(robotId)\n",
    "    kuka_end_effector_idx = 6\n",
    "    #set the gravity\n",
    "    pybullet.setGravity(0, 0, -10)\n",
    "\n",
    "    # create a thread to run the simulation\n",
    "    pybullet.setRealTimeSimulation(1)\n",
    "    \n",
    "    return robotId,kuka_gripper_id\n",
    "\n",
    "robotId,kuka_gripper_id = reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for controlling the robot arm\n",
    "isGrabberOpen = False\n",
    "def openGrabber():\n",
    "    global isGrabberOpen\n",
    "    global kuka_gripper_id\n",
    "    pybullet.setJointMotorControl2(kuka_gripper_id, 4, pybullet.POSITION_CONTROL, targetPosition=0.05, force=100)\n",
    "    pybullet.setJointMotorControl2(kuka_gripper_id, 6, pybullet.POSITION_CONTROL, targetPosition=0.05, force=100)\n",
    "    isGrabberOpen = True\n",
    "\n",
    "def closeGrabber():\n",
    "    global isGrabberOpen\n",
    "    global kuka_gripper_id\n",
    "    pybullet.setJointMotorControl2(kuka_gripper_id, 4, pybullet.POSITION_CONTROL, targetPosition=0, force=100)\n",
    "    pybullet.setJointMotorControl2(kuka_gripper_id, 6, pybullet.POSITION_CONTROL, targetPosition=0, force=100)\n",
    "    isGrabberOpen = False\n",
    "\n",
    "def setEndEffectorPos(pos, orientation):\n",
    "    #first get desired joint positions via inverse kinematics\n",
    "    jointPoses = pybullet.calculateInverseKinematics(robotId, 6, pos, orientation)\n",
    "    for i in range(len(jointPoses)):\n",
    "        if i in FINGER_AXES:\n",
    "            continue\n",
    "            \n",
    "        pybullet.setJointMotorControl2(robotId, i, pybullet.POSITION_CONTROL, targetPosition=jointPoses[i], force=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reset()\n",
    "def getIsOpen():\n",
    "    global isGrabberOpen\n",
    "    return isGrabberOpen\n",
    "\n",
    "def getPointsOnEndEffector(visualize=False):\n",
    "    linkNum = 6\n",
    "    #cet center position\n",
    "    endEffectorPos, endEffectorOrn = pybullet.getLinkState(robotId, linkNum)[:2]\n",
    "    #use orientation to compute the other two points\n",
    "    rotMat = pybullet.getMatrixFromQuaternion(endEffectorOrn)\n",
    "    rotMat = np.array(rotMat).reshape(3,3)\n",
    "    localPos = np.array([0, 0.2, 0])\n",
    "    endEffectorPos2 = endEffectorPos + rotMat.dot(localPos)\n",
    "    localPos = np.array([0.2, 0, 0])\n",
    "    endEffectorPos3 = endEffectorPos + rotMat.dot(localPos)\n",
    "\n",
    "    endState = np.array(endEffectorPos)\n",
    "    endState = np.append(endState, pybullet.getEulerFromQuaternion(endEffectorOrn))\n",
    "\n",
    "    if visualize:\n",
    "        #add small spheres to visualize the points\n",
    "        pybullet.addUserDebugLine(endEffectorPos, endEffectorPos2, [1,0,0], 1, 0.1)\n",
    "        pybullet.addUserDebugLine(endEffectorPos, endEffectorPos3, [0,1,0], 1, 0.1)\n",
    "    \n",
    "    return [endEffectorPos, endEffectorPos2, endEffectorPos3], endState\n",
    "\n",
    "def getTrainingData():\n",
    "    '''return everything in a timestep needed for training (rgb img, depth mask, end effector pos, finger open)\n",
    "    '''\n",
    "\n",
    "    viewMatrix = pybullet.computeViewMatrixFromYawPitchRoll(cameraTargetPosition=[0,0,0.5], distance=1.1, yaw=0, pitch=-45, roll=0, upAxisIndex=2)\n",
    "    projectionMatrix = pybullet.computeProjectionMatrixFOV(fov=60, aspect=float(IMG_WIDTH)/IMG_HEIGHT, nearVal=0.1, farVal=100.0)\n",
    "    image = pybullet.getCameraImage(IMG_WIDTH, IMG_HEIGHT, viewMatrix=viewMatrix, projectionMatrix=projectionMatrix, shadow=1, lightDirection=[1,1,1], lightColor=[1,1,1], lightDistance=1, lightAmbientCoeff=0.5, lightDiffuseCoeff=0.5, lightSpecularCoeff=0.5, renderer=pybullet.ER_BULLET_HARDWARE_OPENGL, flags=pybullet.ER_NO_SEGMENTATION_MASK)\n",
    "\n",
    "    #show the image in frame\n",
    "    width = image[0]\n",
    "    height = image[1]\n",
    "    rgb = image[2]\n",
    "    depth = image[3]\n",
    "    segmentation = image[4]\n",
    "\n",
    "    #convert to numpy array\n",
    "    rgb = np.reshape(rgb, (height, width, 4))\n",
    "    rgb = rgb[:, :, :3] #remove alpha channel\n",
    "    \n",
    "    depth = np.reshape(depth, (height, width))\n",
    "\n",
    "    #get the 3 points on the end effector\n",
    "    endEffectorPoints, endState = getPointsOnEndEffector()\n",
    "\n",
    "    #get if the grabber is open\n",
    "    isOpen = getIsOpen()\n",
    "    \n",
    "    return rgb, depth, endEffectorPoints, endState, isOpen\n",
    "\n",
    "#visualize sample image\n",
    "rgb, depth, endEffectorPoints, endState, isOpen = getTrainingData()\n",
    "plt.imshow(rgb)\n",
    "plt.show()\n",
    "plt.imshow(depth)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Core Env Setup Functions.\n",
    "\n",
    "Run this next section to create training data.  Make sure you have an empty /data/ folder in the same directory as this notebook before proceeding.\n",
    "\n",
    "If you just want to run an existing model, skip to the \"running a model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "isCollectingImgs = False\n",
    "def continuousRecordImgs10Hz():\n",
    "    global runNumber\n",
    "    rgbImgs = []\n",
    "    depthImgs = []\n",
    "    points = []\n",
    "    opens = []\n",
    "    endStates = []\n",
    "    while isCollectingImgs:\n",
    "        startTime = time.time()\n",
    "        rgb, depth, endEffectorPoints, endState, isOpen = getTrainingData()\n",
    "        rgbImgs.append(rgb)\n",
    "        depthImgs.append(depth)\n",
    "        points.append(endEffectorPoints)\n",
    "        endStates.append(endState)\n",
    "        opens.append(isOpen)\n",
    "        endTime = time.time()\n",
    "        sleepTime = 0.1 - (endTime - startTime)\n",
    "        if sleepTime > 0:\n",
    "            time.sleep(sleepTime)\n",
    "        else:\n",
    "            print(\"Warning: Data collection is too slow, took\", endTime - startTime, \"seconds to collect one image\")\n",
    "    \n",
    "    #save the images\n",
    "    dataPath = f\"{DATA_PATH}/{runNumber}\"\n",
    "    os.mkdir(dataPath)\n",
    "    rgbPath = f\"{dataPath}/rgb\"\n",
    "    depthPath = f\"{dataPath}/depth\"\n",
    "    statePath = f\"{dataPath}/states\"\n",
    "    os.mkdir(rgbPath)\n",
    "    os.mkdir(depthPath)\n",
    "    os.mkdir(statePath)\n",
    "\n",
    "    for i in range(len(rgbImgs)):\n",
    "        #convert to bgr for opencv\n",
    "        bgr = rgbImgs[i][:, :, ::-1]\n",
    "        cv2.imwrite(f\"{rgbPath}/rgb{i}.png\", bgr)\n",
    "    \n",
    "    for i in range(len(depthImgs)):\n",
    "        #convert to int\n",
    "        img = (depthImgs[i] * 255).astype(np.uint8)\n",
    "        cv2.imwrite(f\"{depthPath}/depth{i}.png\", img)\n",
    "\n",
    "    #create a csv file with the points and opens for each time step\n",
    "    for i in range(len(points)):\n",
    "        with open(f\"{statePath}/states{i}.csv\", \"w\") as f:\n",
    "            f.write(f'{points[i][0][0]},{points[i][0][1]}')\n",
    "            f.write(f',{points[i][1][0]},{points[i][1][1]}')\n",
    "            f.write(f',{points[i][2][0]},{points[i][2][1]}')\n",
    "            if opens[i]:\n",
    "                f.write(\",1\")\n",
    "            else:\n",
    "                f.write(\",0\")\n",
    "            f.write('\\n')\n",
    "            f.write(f'{endStates[i][0]},{endStates[i][1]},{endStates[i][2]},{endStates[i][3]},{endStates[i][4]},{endStates[i][5]}')      \n",
    "\n",
    "def stopRun():\n",
    "    global runNumber\n",
    "    global isCollectingImgs\n",
    "\n",
    "    #stop data collection for this run\n",
    "    isCollectingImgs = False\n",
    "    time.sleep(0.2) #wait for the thread to stop\n",
    "\n",
    "def startNextRun():\n",
    "    global runNumber\n",
    "    global isCollectingImgs\n",
    "    #start the next run\n",
    "    runNumber += 1\n",
    "    isCollectingImgs = True\n",
    "    thread = threading.Thread(target=continuousRecordImgs10Hz)\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "isRunning = True\n",
    "# pybullet.setVRCameraState(trackObject=robotId)\n",
    "def updateControllerContinuously():\n",
    "    global robotId\n",
    "    lastButtonState = np.zeros(6)\n",
    "    # startNextRun()\n",
    "    while isRunning:\n",
    "        #get the position and orientation of the controller\n",
    "        controllerId = 2\n",
    "        controllerState = pybullet.getVREvents()\n",
    "        for controllerState in controllerState:\n",
    "            id = controllerState[0]\n",
    "            pos = controllerState[1]\n",
    "            orientation = controllerState[2]\n",
    "\n",
    "            if id is not controllerId:\n",
    "                continue\n",
    "\n",
    "            #rotate orientation by 90 degrees in the x axis\n",
    "            orientation = pybullet.getEulerFromQuaternion(orientation)\n",
    "            orientation = list(orientation)\n",
    "            orientation[0] += math.pi\n",
    "            orientation = pybullet.getQuaternionFromEuler(orientation)\n",
    "            \n",
    "            setEndEffectorPos(pos, orientation)\n",
    "\n",
    "            #convert to tuple\n",
    "            orientation = list(orientation)\n",
    "            # controllerState[6][33] front trigger ,controllerState[6][34] side trigger\n",
    "            #if trigger is pressed, close the grabber\n",
    "            if controllerState[6][33] == 1:\n",
    "                closeGrabber()\n",
    "            else:\n",
    "                openGrabber()\n",
    "            buttons = controllerState[6]\n",
    "            #check for menu button\n",
    "            # if buttons[34] == 4:\n",
    "                #reset environment\n",
    "                # stopRun()\n",
    "                # time.sleep(1) #stop mid-reset pictures from being recorded\n",
    "                # robotId = reset()\n",
    "                # time.sleep(1)\n",
    "                # startNextRun()\n",
    "            # else:\n",
    "                # print(buttons[1], lastButtonState[1])\n",
    "            lastButtonState = buttons\n",
    "\n",
    "#start the controller thread\n",
    "thread = threading.Thread(target=updateControllerContinuously)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kill the thread\n",
    "isRunning = False\n",
    "isCollectingImgs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    time.sleep(1)\n",
    "    controllerState = pybullet.getVREvents()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(controllerState[0][3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell kills the pybullet simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(controllerState[0][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the simulation\n",
    "pybullet.disconnect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a pre-trained model.\n",
    "\n",
    "The next few cells load a model.pt file and run it on the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control the robot arm with a deep learning model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VRNet import VRNet\n",
    "from VRNet import DataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VRNet().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "#setup data preprocesser\n",
    "\n",
    "# rgb mean:  tensor([0.5231, 0.5100, 0.4927])\n",
    "# rgb std:  tensor([0.1867, 0.2083, 0.2512])\n",
    "# depth mean:  tensor([0.8959])\n",
    "# depth std:  tensor([0.0430])\n",
    "# states mean:  tensor([ 0.0081, -0.0053,  0.0088,  0.0304,  0.0053,  0.0292,  0.5139],\n",
    "#        device='cuda:0')\n",
    "# states std:  tensor([0.0215, 0.0279, 0.0781, 0.3493, 0.0188, 0.1732, 0.4998],\n",
    "#        device='cuda:0')\n",
    "\n",
    "\n",
    "preprocessor = DataPreprocesser(rgb_mean=torch.tensor([0.5231, 0.5100, 0.4927]), rgb_std=torch.tensor([0.1867, 0.2083, 0.2512]), depth_mean=torch.tensor([0.8959]), depth_std=torch.tensor([0.0430]), \\\n",
    "                        state_mean=torch.tensor([ 0.0081, -0.0053,  0.0088,  0.0304,  0.0053,  0.0292,  0.5139]), state_std=torch.tensor([0.0215, 0.0279, 0.0781, 0.3493, 0.0188, 0.1732, 0.4998]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell creates the model robot controller thread.  After running it, the robot should start moving.  The included model can't get to the cube automatically, but once the robot reaches the cube, the model can place it on the tray.  This failure is likely because of the model simplifications (no auxiliary loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentEndEffectorPose():\n",
    "    global robotId\n",
    "    pos, orientation = pybullet.getLinkState(robotId, 8, computeForwardKinematics=False)[0:2]\n",
    "    z_off = 0.04\n",
    "    pos = [pos[0], pos[1], pos[2] + z_off]\n",
    "    return pos, orientation\n",
    "\n",
    "#in a separate thread, continuously update the robot arm with the model\n",
    "modelControllingRobot = True\n",
    "vels = []\n",
    "def updateRobotNN():\n",
    "    startTime = time.time()\n",
    "    rgb, depth, _, _, _ = getTrainingData()\n",
    "\n",
    "    rgb = torch.from_numpy(rgb).permute(2, 0, 1)\n",
    "    depth = torch.from_numpy(depth)\n",
    "    rgb = rgb.unsqueeze(0).to(device).float() / 255\n",
    "    depth = depth.unsqueeze(0).unsqueeze(0).to(device).float()\n",
    "\n",
    "    #show images with matplotlib\n",
    "    # plt.imshow(rgb[0].permute(1, 2, 0).detach().cpu().numpy())\n",
    "    # plt.show()\n",
    "    # plt.imshow(depth[0].detach().cpu().numpy())\n",
    "    # plt.show()\n",
    "\n",
    "    rgb_norm = preprocessor.normalizeRgb(rgb.cpu()).to(device)\n",
    "    depth_norm = preprocessor.normalizeDepth(depth.cpu()).to(device)\n",
    "    y = model(rgb_norm, depth_norm)\n",
    "\n",
    "    #convert the output to a list of velocities\n",
    "    outputs = y.detach().cpu()\n",
    "    outputs = preprocessor.denormalizeState(outputs)\n",
    "    outputs = outputs[0].numpy()\n",
    "    \n",
    "    Vx, Vy, Vz, Wx, Wy, Wz, grabberOpen = outputs\n",
    "\n",
    "    #compute the next position of the end effector in 100 ms\n",
    "    pos, orn = getCurrentEndEffectorPose()\n",
    "    x, y, z = pos\n",
    "    \n",
    "    x += Vx * 0.5 #use 0.5 instead of 0.1 to make the robot move faster for demos\n",
    "    y += Vy * 0.5\n",
    "    z += Vz * 0.5\n",
    "    # roll += Wx * 0.01 #for simplicity, no angular control\n",
    "    # pitch += Wy * 0.01\n",
    "    # yaw += Wz * 0.01\n",
    "    # vels.append([Vx, Vy, Vz, rgb[0].permute(1, 2, 0).detach().cpu().numpy()])\n",
    "\n",
    "    pos = np.array([x, y, z])\n",
    "    orn = pybullet.getQuaternionFromEuler([0, math.pi, -math.pi/1.7])\n",
    "\n",
    "    #move the robot arm to the next position\n",
    "    setEndEffectorPos(pos, orn)\n",
    "\n",
    "    #open or close the grabber\n",
    "    if grabberOpen > 0.5:\n",
    "        openGrabber()\n",
    "    else:\n",
    "        closeGrabber()\n",
    "    \n",
    "    dt = time.time() - startTime\n",
    "    if dt < 0.1:\n",
    "        time.sleep(0.1 - dt)\n",
    "    else:\n",
    "        print(\"Warning: updateRobotNN took too long: \", dt)\n",
    "\n",
    "def updateRobotContinuous():\n",
    "    while modelControllingRobot:\n",
    "        updateRobotNN()\n",
    "\n",
    "#start the thread\n",
    "thread = threading.Thread(target=updateRobotContinuous)\n",
    "thread.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the robot controller thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelControllingRobot = False\n",
    "reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('pybullet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06b11139e13515c2711c878e587d72e1e158f858f2134781b554bf5f2a3bd4a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
