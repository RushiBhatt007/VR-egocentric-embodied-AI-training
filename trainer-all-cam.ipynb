{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ronak\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\Ronak\\anaconda3\\envs\\torch\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VRNet import VRNet\n",
    "from VRNet import VRDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]\n",
      "rgb mean:  tensor([0.0022, 0.0022, 0.0021])\n",
      "rgb std:  tensor([0.0007, 0.0008, 0.0010])\n",
      "depth mean:  tensor([0.0036])\n",
      "depth std:  tensor([0.0001])\n",
      "states mean:  tensor([-0.0031, -0.0060,  0.0057,  0.0196, -0.0134, -0.0067,  0.0732],\n",
      "       device='cuda:0')\n",
      "states std:  tensor([0.0310, 0.0135, 0.0625, 0.2345, 0.0952, 0.1064, 0.2620],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "dataloader = VRDataLoader('data_all_cam_task_1_augmented', 1, 3, batch_size=128)\n",
    "\n",
    "states = dataloader.states\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#set outliers to 0 (where |x| > 1)\n",
    "for i in range(len(states)):\n",
    "    if abs(states[i][0]) > 1:\n",
    "        #interpolate between two adjacent states\n",
    "        #if either value adjacent is out of bounds, use the other\n",
    "        if i == 0:\n",
    "            states[i][0] = states[i+1][0]\n",
    "        elif i == states.shape[0] - 1:\n",
    "            states[i][0] = states[i-1][0]\n",
    "        else:\n",
    "            states[i][0] = (states[i-1][0] + states[i+1][0]) / 2\n",
    "    if abs(states[i][1]) > 1:\n",
    "        if i == 0:\n",
    "            states[i][1] = states[i+1][1]\n",
    "        elif i == states.shape[0] - 1:\n",
    "            states[i][1] = states[i-1][1]\n",
    "        else:\n",
    "            states[i][1] = (states[i-1][1] + states[i+1][1]) / 2\n",
    "    if abs(states[i][2]) > 1:\n",
    "        if i == 0:\n",
    "            states[i][2] = states[i+1][2]\n",
    "        elif i == states.shape[0] - 1:\n",
    "            states[i][2] = states[i-1][2]\n",
    "        else:\n",
    "            states[i][2] = (states[i-1][2] + states[i+1][2]) / 2\n",
    "\n",
    "#apply a gaussian filter to smooth out the data\n",
    "gaussian_filter = np.array([1, 2, 3, 4, 5, 4, 3, 2, 1])\n",
    "gaussian_filter = gaussian_filter / np.sum(gaussian_filter)\n",
    "\n",
    "states = states.cpu().numpy()\n",
    "for i in range(6):\n",
    "    states[:, i] = np.convolve(states[:, i], gaussian_filter, mode='same')\n",
    "states = torch.tensor(states).to('cuda')\n",
    "\n",
    "# #plot x velocities\n",
    "# plt.plot([state[0].cpu() for state in states][0:500], 'bo')\n",
    "# plt.show()\n",
    "\n",
    "# #plot y velocities\n",
    "# plt.plot([state[1].cpu() for state in states][0:500], 'bo')\n",
    "# plt.show()\n",
    "\n",
    "# #plot z velocities\n",
    "# plt.plot([state[2].cpu() for state in states][0:500], 'bo')\n",
    "# plt.show()\n",
    "\n",
    "# #display Top image\n",
    "# plt.imshow(dataloader.rgbTop_images[0].permute(1,2,0))\n",
    "# plt.show()\n",
    "# #display histogram of Top image\n",
    "# plt.hist(dataloader.rgbTop_images[0].permute(1,2,0).flatten().cpu().numpy())\n",
    "# plt.show()\n",
    "# #display Top image\n",
    "# plt.imshow(dataloader.rgbEff_images[0].permute(1,2,0))\n",
    "# plt.show()\n",
    "# #display histogram of Top image\n",
    "# plt.hist(dataloader.rgbEff_images[0].permute(1,2,0).flatten().cpu().numpy())\n",
    "# plt.show()\n",
    "# #display Top image\n",
    "# plt.imshow(dataloader.rgbSide_images[0].permute(1,2,0))\n",
    "# plt.show()\n",
    "# #display histogram of Top image\n",
    "# plt.hist(dataloader.rgbSide_images[0].permute(1,2,0).flatten().cpu().numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1720,  0.8089,  0.1779,  0.1961, -0.0334, -0.2397,  0.0000],\n",
      "       device='cuda:0')\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#show a random img from the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "idx = 0 #random.randint(0, len(dataloader))\n",
    "data = dataloader[idx]\n",
    "rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img, state = data[0][0], data[1][0], data[2][0], data[3][0], data[4][0], data[5][0], data[6][0]\n",
    "\n",
    "# plt.imshow(rgbTop_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(depthTop_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(rgbEff_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(depthEff_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(rgbSide_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(depthSide_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "print(state)\n",
    "\n",
    "print(len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#add data augmentation\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomAffine(0, shear=3),\n",
    "    torchvision.transforms.RandomAffine(0, scale=(0.98, 1.02)),\n",
    "    # torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.05),\n",
    "    # torchvision.transforms.RandomApply([torchvision.transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))], p=0.5),\n",
    "])\n",
    "\n",
    "def applyTransforms(rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img):\n",
    "    rngstate = torch.random.get_rng_state()\n",
    "    rgbTop_img = transform(rgbTop_img)\n",
    "    rgbEff_img = transform(rgbEff_img)\n",
    "    rgbSide_img = transform(rgbSide_img)\n",
    "    torch.random.set_rng_state(rngstate)\n",
    "    depthTop_img = transform(depthTop_img)\n",
    "    depthEff_img = transform(depthEff_img)\n",
    "    depthSide_img = transform(depthSide_img)\n",
    "    return rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img\n",
    "\n",
    "idx = random.randint(0, len(dataloader))\n",
    "print(idx)\n",
    "data = dataloader[idx]\n",
    "rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img, state = data[0][0], data[1][0], data[2][0], data[3][0], data[4][0], data[5][0], data[6][0]\n",
    "\n",
    "rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img = applyTransforms(rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img)\n",
    "\n",
    "# #apply same transform to both depth and rgb image\n",
    "# plt.imshow(rgbTop_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(depthTop_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(rgbEff_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(depthEff_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(rgbSide_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(depthSide_img.permute(1, 2, 0))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LcLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LcLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss = torch.zeros(pred.shape[0])\n",
    "        for i in range(pred.shape[0]):\n",
    "            p = pred[i]\n",
    "            t = target[i]\n",
    "            loss[i] = torch.arccos(torch.dot(t, p) / (torch.norm(t) * torch.norm(p)))\n",
    "        \n",
    "        return torch.sum(loss)\n",
    "\n",
    "class LgLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LgLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss = torch.zeros(pred.shape[0])\n",
    "        for i in range(pred.shape[0]):\n",
    "            p = pred[i]\n",
    "            t = target[i]\n",
    "            loss[i] = p * torch.log(t) - (1 - p) * torch.log(1 - t)\n",
    "        return torch.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = [1, 0.01, 0.005, 0.0001]\n",
    "\n",
    "def train(model, data_loader, num_epochs, learning_rate, device):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    L1_loss = nn.L1Loss()\n",
    "    L2_loss = nn.MSELoss()\n",
    "    L_c_loss = LcLoss()\n",
    "    L_g_loss = nn.CrossEntropyLoss()\n",
    "    print(len(data_loader))\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(len(data_loader)+1):\n",
    "            rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img, state = data_loader[i]\n",
    "            \n",
    "            # rgb_img = rgb_img\n",
    "            # depth_img = depth_img\n",
    "\n",
    "            #get rgb and depth images\n",
    "            rgbTop_img = rgbTop_img.to(device).float()\n",
    "            depthTop_img = depthTop_img.to(device).float()\n",
    "            rgbEff_img = rgbEff_img.to(device).float()\n",
    "            depthEff_img = depthEff_img.to(device).float()\n",
    "            rgbSide_img = rgbSide_img.to(device).float()\n",
    "            depthSide_img = depthSide_img.to(device).float()\n",
    "            \n",
    "            #apply data augmentation\n",
    "            # rgb_img, depth_img = applyTransforms(rgb_img, depth_img)\n",
    "            \n",
    "            #add batch dimension\n",
    "            state = state.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img)\n",
    "            \n",
    "            #calculate combined loss\n",
    "            # loss = L1_loss(output[0:3], state[0:3]) * loss_weights[0]\n",
    "            #combine 0:3 and 6\n",
    "            important_output = torch.cat((output[:, 0:3], output[:, 6].unsqueeze(1)), dim=1)\n",
    "            important_state = torch.cat((state[:, 0:3], state[:, 6].unsqueeze(1)), dim=1)\n",
    "            \n",
    "            loss = L1_loss(important_output, important_state) # * loss_weights[1]\n",
    "            # loss += L_c_loss(output[:, 0:6], state[:, 0:6]) * loss_weights[2]\n",
    "            # loss += L_g_loss(output[:, 6], state[:, 6]) * loss_weights[3]\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f'Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "# device = torch.device('cuda')\n",
    "model = VRNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0, Iteration: 0, Loss: 0.3843739628791809\n",
      "Epoch: 1, Iteration: 0, Loss: 0.3834558129310608\n",
      "Epoch: 2, Iteration: 0, Loss: 0.3825320601463318\n",
      "Epoch: 3, Iteration: 0, Loss: 0.38159769773483276\n",
      "Epoch: 4, Iteration: 0, Loss: 0.3806588053703308\n",
      "Epoch: 5, Iteration: 0, Loss: 0.37970101833343506\n",
      "Epoch: 6, Iteration: 0, Loss: 0.3787177801132202\n",
      "Epoch: 7, Iteration: 0, Loss: 0.37770387530326843\n",
      "Epoch: 8, Iteration: 0, Loss: 0.3766549527645111\n",
      "Epoch: 9, Iteration: 0, Loss: 0.3755630552768707\n",
      "Epoch: 10, Iteration: 0, Loss: 0.3744245171546936\n",
      "Epoch: 11, Iteration: 0, Loss: 0.3732239902019501\n",
      "Epoch: 12, Iteration: 0, Loss: 0.37195679545402527\n",
      "Epoch: 13, Iteration: 0, Loss: 0.3706015348434448\n",
      "Epoch: 14, Iteration: 0, Loss: 0.3691515028476715\n",
      "Epoch: 15, Iteration: 0, Loss: 0.3675822615623474\n",
      "Epoch: 16, Iteration: 0, Loss: 0.36588791012763977\n",
      "Epoch: 17, Iteration: 0, Loss: 0.3644132614135742\n",
      "Epoch: 18, Iteration: 0, Loss: 0.3646768033504486\n",
      "Epoch: 19, Iteration: 0, Loss: 0.3645457625389099\n",
      "Epoch: 20, Iteration: 0, Loss: 0.36414453387260437\n",
      "Epoch: 21, Iteration: 0, Loss: 0.36357274651527405\n",
      "Epoch: 22, Iteration: 0, Loss: 0.3628281056880951\n",
      "Epoch: 23, Iteration: 0, Loss: 0.3620639741420746\n",
      "Epoch: 24, Iteration: 0, Loss: 0.3612089157104492\n",
      "Epoch: 25, Iteration: 0, Loss: 0.3603047728538513\n",
      "Epoch: 26, Iteration: 0, Loss: 0.3606506884098053\n",
      "Epoch: 27, Iteration: 0, Loss: 0.3608965277671814\n",
      "Epoch: 28, Iteration: 0, Loss: 0.3609485924243927\n",
      "Epoch: 29, Iteration: 0, Loss: 0.36084482073783875\n",
      "Epoch: 30, Iteration: 0, Loss: 0.36060717701911926\n",
      "Epoch: 31, Iteration: 0, Loss: 0.36022719740867615\n",
      "Epoch: 32, Iteration: 0, Loss: 0.3597474694252014\n",
      "Epoch: 33, Iteration: 0, Loss: 0.36007028818130493\n",
      "Epoch: 34, Iteration: 0, Loss: 0.3604566156864166\n",
      "Epoch: 35, Iteration: 0, Loss: 0.3605116009712219\n",
      "Epoch: 36, Iteration: 0, Loss: 0.3602358102798462\n",
      "Epoch: 37, Iteration: 0, Loss: 0.35970908403396606\n",
      "Epoch: 38, Iteration: 0, Loss: 0.3598130941390991\n",
      "Epoch: 39, Iteration: 0, Loss: 0.3600807189941406\n",
      "Epoch: 40, Iteration: 0, Loss: 0.3601754605770111\n",
      "Epoch: 41, Iteration: 0, Loss: 0.3601113259792328\n",
      "Epoch: 42, Iteration: 0, Loss: 0.359904021024704\n",
      "Epoch: 43, Iteration: 0, Loss: 0.3595711290836334\n",
      "Epoch: 44, Iteration: 0, Loss: 0.35932689905166626\n",
      "Epoch: 45, Iteration: 0, Loss: 0.3593899607658386\n",
      "Epoch: 46, Iteration: 0, Loss: 0.35946494340896606\n",
      "Epoch: 47, Iteration: 0, Loss: 0.35932961106300354\n",
      "Epoch: 48, Iteration: 0, Loss: 0.35910382866859436\n",
      "Epoch: 49, Iteration: 0, Loss: 0.359052836894989\n",
      "Epoch: 50, Iteration: 0, Loss: 0.35902270674705505\n",
      "Epoch: 51, Iteration: 0, Loss: 0.3590364158153534\n",
      "Epoch: 52, Iteration: 0, Loss: 0.3589886426925659\n",
      "Epoch: 53, Iteration: 0, Loss: 0.3588731586933136\n",
      "Epoch: 54, Iteration: 0, Loss: 0.35880476236343384\n",
      "Epoch: 55, Iteration: 0, Loss: 0.3587404787540436\n",
      "Epoch: 56, Iteration: 0, Loss: 0.3586692214012146\n",
      "Epoch: 57, Iteration: 0, Loss: 0.35859689116477966\n",
      "Epoch: 58, Iteration: 0, Loss: 0.35851842164993286\n",
      "Epoch: 59, Iteration: 0, Loss: 0.35843491554260254\n",
      "Epoch: 60, Iteration: 0, Loss: 0.3583362102508545\n",
      "Epoch: 61, Iteration: 0, Loss: 0.35822126269340515\n",
      "Epoch: 62, Iteration: 0, Loss: 0.3581031262874603\n",
      "Epoch: 63, Iteration: 0, Loss: 0.3579830825328827\n",
      "Epoch: 64, Iteration: 0, Loss: 0.35786134004592896\n",
      "Epoch: 65, Iteration: 0, Loss: 0.35772940516471863\n",
      "Epoch: 66, Iteration: 0, Loss: 0.3576127290725708\n",
      "Epoch: 67, Iteration: 0, Loss: 0.3574299216270447\n",
      "Epoch: 68, Iteration: 0, Loss: 0.3572968542575836\n",
      "Epoch: 69, Iteration: 0, Loss: 0.35716238617897034\n",
      "Epoch: 70, Iteration: 0, Loss: 0.3570014238357544\n",
      "Epoch: 71, Iteration: 0, Loss: 0.3568111062049866\n",
      "Epoch: 72, Iteration: 0, Loss: 0.3566295802593231\n",
      "Epoch: 73, Iteration: 0, Loss: 0.3564254641532898\n",
      "Epoch: 74, Iteration: 0, Loss: 0.35622498393058777\n",
      "Epoch: 75, Iteration: 0, Loss: 0.35598763823509216\n",
      "Epoch: 76, Iteration: 0, Loss: 0.3557998239994049\n",
      "Epoch: 77, Iteration: 0, Loss: 0.35550060868263245\n",
      "Epoch: 78, Iteration: 0, Loss: 0.35529422760009766\n",
      "Epoch: 79, Iteration: 0, Loss: 0.3550128936767578\n",
      "Epoch: 80, Iteration: 0, Loss: 0.35464027523994446\n",
      "Epoch: 81, Iteration: 0, Loss: 0.3542110025882721\n",
      "Epoch: 82, Iteration: 0, Loss: 0.35386526584625244\n",
      "Epoch: 83, Iteration: 0, Loss: 0.35335657000541687\n",
      "Epoch: 84, Iteration: 0, Loss: 0.352962851524353\n",
      "Epoch: 85, Iteration: 0, Loss: 0.3525069057941437\n",
      "Epoch: 86, Iteration: 0, Loss: 0.3518591523170471\n",
      "Epoch: 87, Iteration: 0, Loss: 0.3511291742324829\n",
      "Epoch: 88, Iteration: 0, Loss: 0.35056403279304504\n",
      "Epoch: 89, Iteration: 0, Loss: 0.3497470021247864\n",
      "Epoch: 90, Iteration: 0, Loss: 0.3489118218421936\n",
      "Epoch: 91, Iteration: 0, Loss: 0.3481311798095703\n",
      "Epoch: 92, Iteration: 0, Loss: 0.3471836447715759\n",
      "Epoch: 93, Iteration: 0, Loss: 0.34609442949295044\n",
      "Epoch: 94, Iteration: 0, Loss: 0.34491509199142456\n",
      "Epoch: 95, Iteration: 0, Loss: 0.3435603082180023\n",
      "Epoch: 96, Iteration: 0, Loss: 0.34196269512176514\n",
      "Epoch: 97, Iteration: 0, Loss: 0.34030741453170776\n",
      "Epoch: 98, Iteration: 0, Loss: 0.33837345242500305\n",
      "Epoch: 99, Iteration: 0, Loss: 0.33655133843421936\n",
      "Epoch: 100, Iteration: 0, Loss: 0.3343604803085327\n",
      "Epoch: 101, Iteration: 0, Loss: 0.33194559812545776\n",
      "Epoch: 102, Iteration: 0, Loss: 0.3292504549026489\n",
      "Epoch: 103, Iteration: 0, Loss: 0.32693660259246826\n",
      "Epoch: 104, Iteration: 0, Loss: 0.3250484764575958\n",
      "Epoch: 105, Iteration: 0, Loss: 0.3236443102359772\n",
      "Epoch: 106, Iteration: 0, Loss: 0.32278579473495483\n",
      "Epoch: 107, Iteration: 0, Loss: 0.3215428590774536\n",
      "Epoch: 108, Iteration: 0, Loss: 0.3207138776779175\n",
      "Epoch: 109, Iteration: 0, Loss: 0.31958600878715515\n",
      "Epoch: 110, Iteration: 0, Loss: 0.3190355598926544\n",
      "Epoch: 111, Iteration: 0, Loss: 0.318181574344635\n",
      "Epoch: 112, Iteration: 0, Loss: 0.3171093165874481\n",
      "Epoch: 113, Iteration: 0, Loss: 0.31651565432548523\n",
      "Epoch: 114, Iteration: 0, Loss: 0.31533682346343994\n",
      "Epoch: 115, Iteration: 0, Loss: 0.3143942952156067\n",
      "Epoch: 116, Iteration: 0, Loss: 0.31359127163887024\n",
      "Epoch: 117, Iteration: 0, Loss: 0.3125894367694855\n",
      "Epoch: 118, Iteration: 0, Loss: 0.31188148260116577\n",
      "Epoch: 119, Iteration: 0, Loss: 0.3110460340976715\n",
      "Epoch: 120, Iteration: 0, Loss: 0.3103245794773102\n",
      "Epoch: 121, Iteration: 0, Loss: 0.30931493639945984\n",
      "Epoch: 122, Iteration: 0, Loss: 0.3082318603992462\n",
      "Epoch: 123, Iteration: 0, Loss: 0.30734965205192566\n",
      "Epoch: 124, Iteration: 0, Loss: 0.30633383989334106\n",
      "Epoch: 125, Iteration: 0, Loss: 0.305569052696228\n",
      "Epoch: 126, Iteration: 0, Loss: 0.30506759881973267\n",
      "Epoch: 127, Iteration: 0, Loss: 0.30370011925697327\n",
      "Epoch: 128, Iteration: 0, Loss: 0.30312931537628174\n",
      "Epoch: 129, Iteration: 0, Loss: 0.3022136688232422\n",
      "Epoch: 130, Iteration: 0, Loss: 0.3012022376060486\n",
      "Epoch: 131, Iteration: 0, Loss: 0.30022159218788147\n",
      "Epoch: 132, Iteration: 0, Loss: 0.2997860610485077\n",
      "Epoch: 133, Iteration: 0, Loss: 0.2979002594947815\n",
      "Epoch: 134, Iteration: 0, Loss: 0.2973661422729492\n",
      "Epoch: 135, Iteration: 0, Loss: 0.2960341274738312\n",
      "Epoch: 136, Iteration: 0, Loss: 0.29544320702552795\n",
      "Epoch: 137, Iteration: 0, Loss: 0.2942555248737335\n",
      "Epoch: 138, Iteration: 0, Loss: 0.29470399022102356\n",
      "Epoch: 139, Iteration: 0, Loss: 0.29355716705322266\n",
      "Epoch: 140, Iteration: 0, Loss: 0.2932174503803253\n",
      "Epoch: 141, Iteration: 0, Loss: 0.2909364700317383\n",
      "Epoch: 142, Iteration: 0, Loss: 0.2890671193599701\n",
      "Epoch: 143, Iteration: 0, Loss: 0.28817859292030334\n",
      "Epoch: 144, Iteration: 0, Loss: 0.28662922978401184\n",
      "Epoch: 145, Iteration: 0, Loss: 0.28584396839141846\n",
      "Epoch: 146, Iteration: 0, Loss: 0.2841504216194153\n",
      "Epoch: 147, Iteration: 0, Loss: 0.28287190198898315\n",
      "Epoch: 148, Iteration: 0, Loss: 0.2813066840171814\n",
      "Epoch: 149, Iteration: 0, Loss: 0.2800719738006592\n",
      "Epoch: 150, Iteration: 0, Loss: 0.27944451570510864\n",
      "Epoch: 151, Iteration: 0, Loss: 0.27729251980781555\n",
      "Epoch: 152, Iteration: 0, Loss: 0.2762942314147949\n",
      "Epoch: 153, Iteration: 0, Loss: 0.2744261622428894\n",
      "Epoch: 154, Iteration: 0, Loss: 0.27366575598716736\n",
      "Epoch: 155, Iteration: 0, Loss: 0.27152019739151\n",
      "Epoch: 156, Iteration: 0, Loss: 0.2724184989929199\n",
      "Epoch: 157, Iteration: 0, Loss: 0.27198144793510437\n",
      "Epoch: 158, Iteration: 0, Loss: 0.26972144842147827\n",
      "Epoch: 159, Iteration: 0, Loss: 0.26812106370925903\n",
      "Epoch: 160, Iteration: 0, Loss: 0.26724427938461304\n",
      "Epoch: 161, Iteration: 0, Loss: 0.2636036276817322\n",
      "Epoch: 162, Iteration: 0, Loss: 0.26223117113113403\n",
      "Epoch: 163, Iteration: 0, Loss: 0.26207712292671204\n",
      "Epoch: 164, Iteration: 0, Loss: 0.25903069972991943\n",
      "Epoch: 165, Iteration: 0, Loss: 0.2583422362804413\n",
      "Epoch: 166, Iteration: 0, Loss: 0.2558349072933197\n",
      "Epoch: 167, Iteration: 0, Loss: 0.25328660011291504\n",
      "Epoch: 168, Iteration: 0, Loss: 0.25133016705513\n",
      "Epoch: 169, Iteration: 0, Loss: 0.24890823662281036\n",
      "Epoch: 170, Iteration: 0, Loss: 0.24757325649261475\n",
      "Epoch: 171, Iteration: 0, Loss: 0.2449323982000351\n",
      "Epoch: 172, Iteration: 0, Loss: 0.2444816380739212\n",
      "Epoch: 173, Iteration: 0, Loss: 0.24034132063388824\n",
      "Epoch: 174, Iteration: 0, Loss: 0.23861439526081085\n",
      "Epoch: 175, Iteration: 0, Loss: 0.23846036195755005\n",
      "Epoch: 176, Iteration: 0, Loss: 0.23413008451461792\n",
      "Epoch: 177, Iteration: 0, Loss: 0.23391620814800262\n",
      "Epoch: 178, Iteration: 0, Loss: 0.23143376410007477\n",
      "Epoch: 179, Iteration: 0, Loss: 0.22503961622714996\n",
      "Epoch: 180, Iteration: 0, Loss: 0.23067675530910492\n",
      "Epoch: 181, Iteration: 0, Loss: 0.22212648391723633\n",
      "Epoch: 182, Iteration: 0, Loss: 0.22409072518348694\n",
      "Epoch: 183, Iteration: 0, Loss: 0.22634272277355194\n",
      "Epoch: 184, Iteration: 0, Loss: 0.2222364842891693\n",
      "Epoch: 185, Iteration: 0, Loss: 0.21907354891300201\n",
      "Epoch: 186, Iteration: 0, Loss: 0.2200375199317932\n",
      "Epoch: 187, Iteration: 0, Loss: 0.22282341122627258\n",
      "Epoch: 188, Iteration: 0, Loss: 0.21334387362003326\n",
      "Epoch: 189, Iteration: 0, Loss: 0.21500438451766968\n",
      "Epoch: 190, Iteration: 0, Loss: 0.20959120988845825\n",
      "Epoch: 191, Iteration: 0, Loss: 0.2144172340631485\n",
      "Epoch: 192, Iteration: 0, Loss: 0.21019065380096436\n",
      "Epoch: 193, Iteration: 0, Loss: 0.20470860600471497\n",
      "Epoch: 194, Iteration: 0, Loss: 0.20643645524978638\n",
      "Epoch: 195, Iteration: 0, Loss: 0.20442475378513336\n",
      "Epoch: 196, Iteration: 0, Loss: 0.19701489806175232\n",
      "Epoch: 197, Iteration: 0, Loss: 0.20401309430599213\n",
      "Epoch: 198, Iteration: 0, Loss: 0.2159702479839325\n",
      "Epoch: 199, Iteration: 0, Loss: 0.21139855682849884\n",
      "Epoch: 200, Iteration: 0, Loss: 0.20443952083587646\n",
      "Epoch: 201, Iteration: 0, Loss: 0.2046785056591034\n",
      "Epoch: 202, Iteration: 0, Loss: 0.19871821999549866\n",
      "Epoch: 203, Iteration: 0, Loss: 0.1979691982269287\n",
      "Epoch: 204, Iteration: 0, Loss: 0.19457857310771942\n",
      "Epoch: 205, Iteration: 0, Loss: 0.18986164033412933\n",
      "Epoch: 206, Iteration: 0, Loss: 0.19669415056705475\n",
      "Epoch: 207, Iteration: 0, Loss: 0.19433201849460602\n",
      "Epoch: 208, Iteration: 0, Loss: 0.2073983997106552\n",
      "Epoch: 209, Iteration: 0, Loss: 0.1952654868364334\n",
      "Epoch: 210, Iteration: 0, Loss: 0.20637506246566772\n",
      "Epoch: 211, Iteration: 0, Loss: 0.20379747450351715\n",
      "Epoch: 212, Iteration: 0, Loss: 0.20364239811897278\n",
      "Epoch: 213, Iteration: 0, Loss: 0.20051807165145874\n",
      "Epoch: 214, Iteration: 0, Loss: 0.19383271038532257\n",
      "Epoch: 215, Iteration: 0, Loss: 0.19137442111968994\n",
      "Epoch: 216, Iteration: 0, Loss: 0.19075939059257507\n",
      "Epoch: 217, Iteration: 0, Loss: 0.18788260221481323\n",
      "Epoch: 218, Iteration: 0, Loss: 0.18936999142169952\n",
      "Epoch: 219, Iteration: 0, Loss: 0.18396513164043427\n",
      "Epoch: 220, Iteration: 0, Loss: 0.175582617521286\n",
      "Epoch: 221, Iteration: 0, Loss: 0.17731888592243195\n",
      "Epoch: 222, Iteration: 0, Loss: 0.18128716945648193\n",
      "Epoch: 223, Iteration: 0, Loss: 0.1791732758283615\n",
      "Epoch: 224, Iteration: 0, Loss: 0.1774214804172516\n",
      "Epoch: 225, Iteration: 0, Loss: 0.1739410012960434\n",
      "Epoch: 226, Iteration: 0, Loss: 0.16622626781463623\n",
      "Epoch: 227, Iteration: 0, Loss: 0.16876539587974548\n",
      "Epoch: 228, Iteration: 0, Loss: 0.1644487977027893\n",
      "Epoch: 229, Iteration: 0, Loss: 0.16340278089046478\n",
      "Epoch: 230, Iteration: 0, Loss: 0.1594473272562027\n",
      "Epoch: 231, Iteration: 0, Loss: 0.16061480343341827\n",
      "Epoch: 232, Iteration: 0, Loss: 0.15968285501003265\n",
      "Epoch: 233, Iteration: 0, Loss: 0.15548068284988403\n",
      "Epoch: 234, Iteration: 0, Loss: 0.1562182456254959\n",
      "Epoch: 235, Iteration: 0, Loss: 0.1524769812822342\n",
      "Epoch: 236, Iteration: 0, Loss: 0.15231207013130188\n",
      "Epoch: 237, Iteration: 0, Loss: 0.14958731830120087\n",
      "Epoch: 238, Iteration: 0, Loss: 0.14961539208889008\n",
      "Epoch: 239, Iteration: 0, Loss: 0.1474124789237976\n",
      "Epoch: 240, Iteration: 0, Loss: 0.14855335652828217\n",
      "Epoch: 241, Iteration: 0, Loss: 0.14333957433700562\n",
      "Epoch: 242, Iteration: 0, Loss: 0.14231178164482117\n",
      "Epoch: 243, Iteration: 0, Loss: 0.14083190262317657\n",
      "Epoch: 244, Iteration: 0, Loss: 0.13946178555488586\n",
      "Epoch: 245, Iteration: 0, Loss: 0.13965831696987152\n",
      "Epoch: 246, Iteration: 0, Loss: 0.13694006204605103\n",
      "Epoch: 247, Iteration: 0, Loss: 0.13515663146972656\n",
      "Epoch: 248, Iteration: 0, Loss: 0.1373845785856247\n",
      "Epoch: 249, Iteration: 0, Loss: 0.13512082397937775\n",
      "Epoch: 250, Iteration: 0, Loss: 0.1341763436794281\n",
      "Epoch: 251, Iteration: 0, Loss: 0.13238440454006195\n",
      "Epoch: 252, Iteration: 0, Loss: 0.13367296755313873\n",
      "Epoch: 253, Iteration: 0, Loss: 0.1325778067111969\n",
      "Epoch: 254, Iteration: 0, Loss: 0.13140010833740234\n",
      "Epoch: 255, Iteration: 0, Loss: 0.13245703279972076\n",
      "Epoch: 256, Iteration: 0, Loss: 0.126290425658226\n",
      "Epoch: 257, Iteration: 0, Loss: 0.13097108900547028\n",
      "Epoch: 258, Iteration: 0, Loss: 0.13354985415935516\n",
      "Epoch: 259, Iteration: 0, Loss: 0.13083982467651367\n",
      "Epoch: 260, Iteration: 0, Loss: 0.1256866157054901\n",
      "Epoch: 261, Iteration: 0, Loss: 0.13004618883132935\n",
      "Epoch: 262, Iteration: 0, Loss: 0.125680610537529\n",
      "Epoch: 263, Iteration: 0, Loss: 0.1232714131474495\n",
      "Epoch: 264, Iteration: 0, Loss: 0.12578114867210388\n",
      "Epoch: 265, Iteration: 0, Loss: 0.12229489535093307\n",
      "Epoch: 266, Iteration: 0, Loss: 0.12187996506690979\n",
      "Epoch: 267, Iteration: 0, Loss: 0.11937350034713745\n",
      "Epoch: 268, Iteration: 0, Loss: 0.12067367881536484\n",
      "Epoch: 269, Iteration: 0, Loss: 0.11997184157371521\n",
      "Epoch: 270, Iteration: 0, Loss: 0.12234601378440857\n",
      "Epoch: 271, Iteration: 0, Loss: 0.12912936508655548\n",
      "Epoch: 272, Iteration: 0, Loss: 0.12193404883146286\n",
      "Epoch: 273, Iteration: 0, Loss: 0.1294272243976593\n",
      "Epoch: 274, Iteration: 0, Loss: 0.13331535458564758\n",
      "Epoch: 275, Iteration: 0, Loss: 0.12613379955291748\n",
      "Epoch: 276, Iteration: 0, Loss: 0.1209133118391037\n",
      "Epoch: 277, Iteration: 0, Loss: 0.12036432325839996\n",
      "Epoch: 278, Iteration: 0, Loss: 0.11649417132139206\n",
      "Epoch: 279, Iteration: 0, Loss: 0.1343897581100464\n",
      "Epoch: 280, Iteration: 0, Loss: 0.11709873378276825\n",
      "Epoch: 281, Iteration: 0, Loss: 0.12419223040342331\n",
      "Epoch: 282, Iteration: 0, Loss: 0.12807251513004303\n",
      "Epoch: 283, Iteration: 0, Loss: 0.1309070587158203\n",
      "Epoch: 284, Iteration: 0, Loss: 0.1234205961227417\n",
      "Epoch: 285, Iteration: 0, Loss: 0.11513353884220123\n",
      "Epoch: 286, Iteration: 0, Loss: 0.1132504865527153\n",
      "Epoch: 287, Iteration: 0, Loss: 0.11127236485481262\n",
      "Epoch: 288, Iteration: 0, Loss: 0.12903696298599243\n",
      "Epoch: 289, Iteration: 0, Loss: 0.11104509979486465\n",
      "Epoch: 290, Iteration: 0, Loss: 0.1173967570066452\n",
      "Epoch: 291, Iteration: 0, Loss: 0.11780531704425812\n",
      "Epoch: 292, Iteration: 0, Loss: 0.12293165177106857\n",
      "Epoch: 293, Iteration: 0, Loss: 0.12309543788433075\n",
      "Epoch: 294, Iteration: 0, Loss: 0.11647569388151169\n",
      "Epoch: 295, Iteration: 0, Loss: 0.11115232110023499\n",
      "Epoch: 296, Iteration: 0, Loss: 0.11116401851177216\n",
      "Epoch: 297, Iteration: 0, Loss: 0.10976686328649521\n",
      "Epoch: 298, Iteration: 0, Loss: 0.10791461914777756\n",
      "Epoch: 299, Iteration: 0, Loss: 0.11172964423894882\n",
      "Epoch: 300, Iteration: 0, Loss: 0.10750328004360199\n",
      "Epoch: 301, Iteration: 0, Loss: 0.10693193972110748\n",
      "Epoch: 302, Iteration: 0, Loss: 0.10635637491941452\n",
      "Epoch: 303, Iteration: 0, Loss: 0.10564430058002472\n",
      "Epoch: 304, Iteration: 0, Loss: 0.1059107705950737\n",
      "Epoch: 305, Iteration: 0, Loss: 0.10150571912527084\n",
      "Epoch: 306, Iteration: 0, Loss: 0.1033405140042305\n",
      "Epoch: 307, Iteration: 0, Loss: 0.10384803265333176\n",
      "Epoch: 308, Iteration: 0, Loss: 0.10198856890201569\n",
      "Epoch: 309, Iteration: 0, Loss: 0.10297359526157379\n",
      "Epoch: 310, Iteration: 0, Loss: 0.10190372914075851\n",
      "Epoch: 311, Iteration: 0, Loss: 0.10134626924991608\n",
      "Epoch: 312, Iteration: 0, Loss: 0.10068699717521667\n",
      "Epoch: 313, Iteration: 0, Loss: 0.09998258203268051\n",
      "Epoch: 314, Iteration: 0, Loss: 0.09977217018604279\n",
      "Epoch: 315, Iteration: 0, Loss: 0.09882057458162308\n",
      "Epoch: 316, Iteration: 0, Loss: 0.09756924957036972\n",
      "Epoch: 317, Iteration: 0, Loss: 0.09941505640745163\n",
      "Epoch: 318, Iteration: 0, Loss: 0.09915617853403091\n",
      "Epoch: 319, Iteration: 0, Loss: 0.09823740273714066\n",
      "Epoch: 320, Iteration: 0, Loss: 0.09883975982666016\n",
      "Epoch: 321, Iteration: 0, Loss: 0.09766215085983276\n",
      "Epoch: 322, Iteration: 0, Loss: 0.09690038114786148\n",
      "Epoch: 323, Iteration: 0, Loss: 0.09741263836622238\n",
      "Epoch: 324, Iteration: 0, Loss: 0.09711045026779175\n",
      "Epoch: 325, Iteration: 0, Loss: 0.09716475754976273\n",
      "Epoch: 326, Iteration: 0, Loss: 0.09536737948656082\n",
      "Epoch: 327, Iteration: 0, Loss: 0.09615112841129303\n",
      "Epoch: 328, Iteration: 0, Loss: 0.09577980637550354\n",
      "Epoch: 329, Iteration: 0, Loss: 0.09573398530483246\n",
      "Epoch: 330, Iteration: 0, Loss: 0.09554266184568405\n",
      "Epoch: 331, Iteration: 0, Loss: 0.09497112780809402\n",
      "Epoch: 332, Iteration: 0, Loss: 0.09470463544130325\n",
      "Epoch: 333, Iteration: 0, Loss: 0.09463533014059067\n",
      "Epoch: 334, Iteration: 0, Loss: 0.0936250165104866\n",
      "Epoch: 335, Iteration: 0, Loss: 0.09596972167491913\n",
      "Epoch: 336, Iteration: 0, Loss: 0.09350400418043137\n",
      "Epoch: 337, Iteration: 0, Loss: 0.09536930173635483\n",
      "Epoch: 338, Iteration: 0, Loss: 0.09419142454862595\n",
      "Epoch: 339, Iteration: 0, Loss: 0.09491629153490067\n",
      "Epoch: 340, Iteration: 0, Loss: 0.09508068859577179\n",
      "Epoch: 341, Iteration: 0, Loss: 0.0934193879365921\n",
      "Epoch: 342, Iteration: 0, Loss: 0.09455706179141998\n",
      "Epoch: 343, Iteration: 0, Loss: 0.09317527711391449\n",
      "Epoch: 344, Iteration: 0, Loss: 0.09249790757894516\n",
      "Epoch: 345, Iteration: 0, Loss: 0.09312469512224197\n",
      "Epoch: 346, Iteration: 0, Loss: 0.09271589666604996\n",
      "Epoch: 347, Iteration: 0, Loss: 0.09198518842458725\n",
      "Epoch: 348, Iteration: 0, Loss: 0.09085431694984436\n",
      "Epoch: 349, Iteration: 0, Loss: 0.09186068177223206\n",
      "Epoch: 350, Iteration: 0, Loss: 0.09227680414915085\n",
      "Epoch: 351, Iteration: 0, Loss: 0.0911976769566536\n",
      "Epoch: 352, Iteration: 0, Loss: 0.09072360396385193\n",
      "Epoch: 353, Iteration: 0, Loss: 0.09074831008911133\n",
      "Epoch: 354, Iteration: 0, Loss: 0.09029999375343323\n",
      "Epoch: 355, Iteration: 0, Loss: 0.09059320390224457\n",
      "Epoch: 356, Iteration: 0, Loss: 0.09104474633932114\n",
      "Epoch: 357, Iteration: 0, Loss: 0.09143803268671036\n",
      "Epoch: 358, Iteration: 0, Loss: 0.09049952775239944\n",
      "Epoch: 359, Iteration: 0, Loss: 0.09026908129453659\n",
      "Epoch: 360, Iteration: 0, Loss: 0.08929822593927383\n",
      "Epoch: 361, Iteration: 0, Loss: 0.08906422555446625\n",
      "Epoch: 362, Iteration: 0, Loss: 0.0899040475487709\n",
      "Epoch: 363, Iteration: 0, Loss: 0.08861225098371506\n",
      "Epoch: 364, Iteration: 0, Loss: 0.08943327516317368\n",
      "Epoch: 365, Iteration: 0, Loss: 0.08908379822969437\n",
      "Epoch: 366, Iteration: 0, Loss: 0.0885745957493782\n",
      "Epoch: 367, Iteration: 0, Loss: 0.08902586996555328\n",
      "Epoch: 368, Iteration: 0, Loss: 0.0902927964925766\n",
      "Epoch: 369, Iteration: 0, Loss: 0.08951699733734131\n",
      "Epoch: 370, Iteration: 0, Loss: 0.08897246420383453\n",
      "Epoch: 371, Iteration: 0, Loss: 0.08953903615474701\n",
      "Epoch: 372, Iteration: 0, Loss: 0.08868227899074554\n",
      "Epoch: 373, Iteration: 0, Loss: 0.08937600255012512\n",
      "Epoch: 374, Iteration: 0, Loss: 0.08735999464988708\n",
      "Epoch: 375, Iteration: 0, Loss: 0.08988960832357407\n",
      "Epoch: 376, Iteration: 0, Loss: 0.08787576854228973\n",
      "Epoch: 377, Iteration: 0, Loss: 0.08846040815114975\n",
      "Epoch: 378, Iteration: 0, Loss: 0.0865410640835762\n",
      "Epoch: 379, Iteration: 0, Loss: 0.08811580389738083\n",
      "Epoch: 380, Iteration: 0, Loss: 0.0866825059056282\n",
      "Epoch: 381, Iteration: 0, Loss: 0.08688391745090485\n",
      "Epoch: 382, Iteration: 0, Loss: 0.08552124351263046\n",
      "Epoch: 383, Iteration: 0, Loss: 0.08813001960515976\n",
      "Epoch: 384, Iteration: 0, Loss: 0.08580141514539719\n",
      "Epoch: 385, Iteration: 0, Loss: 0.08626386523246765\n",
      "Epoch: 386, Iteration: 0, Loss: 0.08586135506629944\n",
      "Epoch: 387, Iteration: 0, Loss: 0.0870068296790123\n",
      "Epoch: 388, Iteration: 0, Loss: 0.08641672134399414\n",
      "Epoch: 389, Iteration: 0, Loss: 0.08617772907018661\n",
      "Epoch: 390, Iteration: 0, Loss: 0.08478762954473495\n",
      "Epoch: 391, Iteration: 0, Loss: 0.08762088418006897\n",
      "Epoch: 392, Iteration: 0, Loss: 0.08573845773935318\n",
      "Epoch: 393, Iteration: 0, Loss: 0.08646199852228165\n",
      "Epoch: 394, Iteration: 0, Loss: 0.08498384058475494\n",
      "Epoch: 395, Iteration: 0, Loss: 0.08527641743421555\n",
      "Epoch: 396, Iteration: 0, Loss: 0.0844932496547699\n",
      "Epoch: 397, Iteration: 0, Loss: 0.08574339747428894\n",
      "Epoch: 398, Iteration: 0, Loss: 0.08403602242469788\n",
      "Epoch: 399, Iteration: 0, Loss: 0.08446307480335236\n",
      "Epoch: 400, Iteration: 0, Loss: 0.08428207039833069\n",
      "Epoch: 401, Iteration: 0, Loss: 0.08363094180822372\n",
      "Epoch: 402, Iteration: 0, Loss: 0.08373488485813141\n",
      "Epoch: 403, Iteration: 0, Loss: 0.08286537230014801\n",
      "Epoch: 404, Iteration: 0, Loss: 0.08300499618053436\n",
      "Epoch: 405, Iteration: 0, Loss: 0.0841980054974556\n",
      "Epoch: 406, Iteration: 0, Loss: 0.08286409825086594\n",
      "Epoch: 407, Iteration: 0, Loss: 0.08235625177621841\n",
      "Epoch: 408, Iteration: 0, Loss: 0.0831536203622818\n",
      "Epoch: 409, Iteration: 0, Loss: 0.08247335255146027\n",
      "Epoch: 410, Iteration: 0, Loss: 0.0855230763554573\n",
      "Epoch: 411, Iteration: 0, Loss: 0.0817217081785202\n",
      "Epoch: 412, Iteration: 0, Loss: 0.08230502158403397\n",
      "Epoch: 413, Iteration: 0, Loss: 0.08232423663139343\n",
      "Epoch: 414, Iteration: 0, Loss: 0.08167611062526703\n",
      "Epoch: 415, Iteration: 0, Loss: 0.0813523381948471\n",
      "Epoch: 416, Iteration: 0, Loss: 0.08069048076868057\n",
      "Epoch: 417, Iteration: 0, Loss: 0.08146633207798004\n",
      "Epoch: 418, Iteration: 0, Loss: 0.0805661603808403\n",
      "Epoch: 419, Iteration: 0, Loss: 0.08114849030971527\n",
      "Epoch: 420, Iteration: 0, Loss: 0.08118083328008652\n",
      "Epoch: 421, Iteration: 0, Loss: 0.08116941154003143\n",
      "Epoch: 422, Iteration: 0, Loss: 0.08217883855104446\n",
      "Epoch: 423, Iteration: 0, Loss: 0.08175148069858551\n",
      "Epoch: 424, Iteration: 0, Loss: 0.08098991960287094\n",
      "Epoch: 425, Iteration: 0, Loss: 0.08033666014671326\n",
      "Epoch: 426, Iteration: 0, Loss: 0.08011583983898163\n",
      "Epoch: 427, Iteration: 0, Loss: 0.08005163818597794\n",
      "Epoch: 428, Iteration: 0, Loss: 0.07986455410718918\n",
      "Epoch: 429, Iteration: 0, Loss: 0.08065300434827805\n",
      "Epoch: 430, Iteration: 0, Loss: 0.07985274493694305\n",
      "Epoch: 431, Iteration: 0, Loss: 0.07912945002317429\n",
      "Epoch: 432, Iteration: 0, Loss: 0.07970434427261353\n",
      "Epoch: 433, Iteration: 0, Loss: 0.07903473824262619\n",
      "Epoch: 434, Iteration: 0, Loss: 0.07971415668725967\n",
      "Epoch: 435, Iteration: 0, Loss: 0.0790986716747284\n",
      "Epoch: 436, Iteration: 0, Loss: 0.08078693598508835\n",
      "Epoch: 437, Iteration: 0, Loss: 0.07936212420463562\n",
      "Epoch: 438, Iteration: 0, Loss: 0.07929595559835434\n",
      "Epoch: 439, Iteration: 0, Loss: 0.07863634079694748\n",
      "Epoch: 440, Iteration: 0, Loss: 0.07837953418493271\n",
      "Epoch: 441, Iteration: 0, Loss: 0.07860321551561356\n",
      "Epoch: 442, Iteration: 0, Loss: 0.07891342788934708\n",
      "Epoch: 443, Iteration: 0, Loss: 0.07767146825790405\n",
      "Epoch: 444, Iteration: 0, Loss: 0.078948974609375\n",
      "Epoch: 445, Iteration: 0, Loss: 0.07907547056674957\n",
      "Epoch: 446, Iteration: 0, Loss: 0.07800191640853882\n",
      "Epoch: 447, Iteration: 0, Loss: 0.08047016710042953\n",
      "Epoch: 448, Iteration: 0, Loss: 0.07845579087734222\n",
      "Epoch: 449, Iteration: 0, Loss: 0.08030346781015396\n",
      "Epoch: 450, Iteration: 0, Loss: 0.08009171485900879\n",
      "Epoch: 451, Iteration: 0, Loss: 0.0779591053724289\n",
      "Epoch: 452, Iteration: 0, Loss: 0.07892173528671265\n",
      "Epoch: 453, Iteration: 0, Loss: 0.07795199006795883\n",
      "Epoch: 454, Iteration: 0, Loss: 0.07886337488889694\n",
      "Epoch: 455, Iteration: 0, Loss: 0.0771922618150711\n",
      "Epoch: 456, Iteration: 0, Loss: 0.07885587215423584\n",
      "Epoch: 457, Iteration: 0, Loss: 0.07689797878265381\n",
      "Epoch: 458, Iteration: 0, Loss: 0.07981329411268234\n",
      "Epoch: 459, Iteration: 0, Loss: 0.0788518488407135\n",
      "Epoch: 460, Iteration: 0, Loss: 0.07774011045694351\n",
      "Epoch: 461, Iteration: 0, Loss: 0.0783776268362999\n",
      "Epoch: 462, Iteration: 0, Loss: 0.07710271328687668\n",
      "Epoch: 463, Iteration: 0, Loss: 0.07770849764347076\n",
      "Epoch: 464, Iteration: 0, Loss: 0.07560659945011139\n",
      "Epoch: 465, Iteration: 0, Loss: 0.07700026035308838\n",
      "Epoch: 466, Iteration: 0, Loss: 0.0751468762755394\n",
      "Epoch: 467, Iteration: 0, Loss: 0.07699345052242279\n",
      "Epoch: 468, Iteration: 0, Loss: 0.07526817172765732\n",
      "Epoch: 469, Iteration: 0, Loss: 0.07711520791053772\n",
      "Epoch: 470, Iteration: 0, Loss: 0.07580135762691498\n",
      "Epoch: 471, Iteration: 0, Loss: 0.07609333097934723\n",
      "Epoch: 472, Iteration: 0, Loss: 0.07718336582183838\n",
      "Epoch: 473, Iteration: 0, Loss: 0.07557903230190277\n",
      "Epoch: 474, Iteration: 0, Loss: 0.07626743614673615\n",
      "Epoch: 475, Iteration: 0, Loss: 0.07458960264921188\n",
      "Epoch: 476, Iteration: 0, Loss: 0.07545067369937897\n",
      "Epoch: 477, Iteration: 0, Loss: 0.07409361749887466\n",
      "Epoch: 478, Iteration: 0, Loss: 0.07443100959062576\n",
      "Epoch: 479, Iteration: 0, Loss: 0.07452428340911865\n",
      "Epoch: 480, Iteration: 0, Loss: 0.07339444756507874\n",
      "Epoch: 481, Iteration: 0, Loss: 0.07346585392951965\n",
      "Epoch: 482, Iteration: 0, Loss: 0.07315150648355484\n",
      "Epoch: 483, Iteration: 0, Loss: 0.07335267961025238\n",
      "Epoch: 484, Iteration: 0, Loss: 0.07345766574144363\n",
      "Epoch: 485, Iteration: 0, Loss: 0.07260553538799286\n",
      "Epoch: 486, Iteration: 0, Loss: 0.0721125602722168\n",
      "Epoch: 487, Iteration: 0, Loss: 0.07332991063594818\n",
      "Epoch: 488, Iteration: 0, Loss: 0.07274904102087021\n",
      "Epoch: 489, Iteration: 0, Loss: 0.07319623231887817\n",
      "Epoch: 490, Iteration: 0, Loss: 0.07409504055976868\n",
      "Epoch: 491, Iteration: 0, Loss: 0.0721539855003357\n",
      "Epoch: 492, Iteration: 0, Loss: 0.07470517605543137\n",
      "Epoch: 493, Iteration: 0, Loss: 0.07246322184801102\n",
      "Epoch: 494, Iteration: 0, Loss: 0.07306839525699615\n",
      "Epoch: 495, Iteration: 0, Loss: 0.07226699590682983\n",
      "Epoch: 496, Iteration: 0, Loss: 0.07149916142225266\n",
      "Epoch: 497, Iteration: 0, Loss: 0.07157519459724426\n",
      "Epoch: 498, Iteration: 0, Loss: 0.07035917043685913\n",
      "Epoch: 499, Iteration: 0, Loss: 0.07148255407810211\n"
     ]
    }
   ],
   "source": [
    "train(model, dataloader, 500, 0.0005, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 120, 160]) torch.Size([1, 1, 120, 160])\n",
      "output: -1.189643144607544 -0.41878265142440796 0.8808656334877014 0.9935423135757446\n",
      "mse:  0.34184054\n",
      "tensor([-1.1834, -0.4046,  0.9315,  0.5629, -1.3584,  0.4810,  1.0000],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#test model on an example image\n",
    "import numpy as np\n",
    "import random\n",
    "idx = random.randint(0, len(dataloader))\n",
    "rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img, state = data[0][0], data[1][0], data[2][0], data[3][0], data[4][0], data[5][0], data[6][0]\n",
    "\n",
    "model.eval()\n",
    "rgbTop_img = rgbTop_img.unsqueeze(0).to(device).float() \n",
    "depthTop_img = depthTop_img.unsqueeze(0).to(device).float()\n",
    "rgbEff_img = rgbEff_img.unsqueeze(0).to(device).float() \n",
    "depthEff_img = depthEff_img.unsqueeze(0).to(device).float()\n",
    "rgbSide_img = rgbSide_img.unsqueeze(0).to(device).float() \n",
    "depthSide_img = depthSide_img.unsqueeze(0).to(device).float()\n",
    "\n",
    "\n",
    "rgbTop_img = rgbTop_img.permute(0, 1, 2, 3)\n",
    "depthTop_img = depthTop_img.permute(0, 1, 2, 3)\n",
    "rgbEff_img = rgbEff_img.permute(0, 1, 2, 3)\n",
    "depthEff_img = depthEff_img.permute(0, 1, 2, 3)\n",
    "rgbSide_img = rgbSide_img.permute(0, 1, 2, 3)\n",
    "depthSide_img = depthSide_img.permute(0, 1, 2, 3)\n",
    "\n",
    "print(rgbTop_img.shape, depthTop_img.shape)\n",
    "\n",
    "output = model(rgbTop_img, depthTop_img, rgbEff_img, depthEff_img, rgbSide_img, depthSide_img)\n",
    "\n",
    "#show output (no scientific notation)\n",
    "print('output: {} {} {} {}'.format(output[0][0].item(), output[0][1].item(), output[0][2].item(), output[0][6].item(),))\n",
    "print('mse: ', np.mean((output.detach().cpu().numpy()[0:2] - state.detach().cpu().numpy())[0:2] ** 2))\n",
    "print(state)\n",
    "\n",
    "# print(rgb_img.shape)\n",
    "# plt.imshow(rgb_img.permute(0, 2, 3, 1).cpu()[0])\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(rgb_img.permute(0, 2, 3, 1).cpu()[0])\n",
    "# plt.savefig(depth_img.permute(0, 2, 3, 1).cpu()[0])\n",
    "# plt.imshow(depth_img.permute(0, 2, 3, 1).cpu()[0])\n",
    "# plt.show()\n",
    "\n",
    "# print(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'model_all_cam_task3.pt'\n",
    "#save the model\n",
    "torch.save(model.state_dict(), model_name)\n",
    "\n",
    "#load the model\n",
    "model = VRNet().to(device)\n",
    "model.load_state_dict(torch.load(model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85eab4bc6c6c5de8d8c9b73424489217eb3ac6fe3bc76caf6b2eb1d4f520884f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
