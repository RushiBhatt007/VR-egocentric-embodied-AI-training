{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info\n",
    "\n",
    "\n",
    "/data/\n",
    " - /{runNumber}/\n",
    "   - /depth/ - contains 1 channel depth images\n",
    "      - fileNames: depth{stepNum}.png\n",
    "   - /rgb/ - contains 3 channel rgb images\n",
    "      - fileNames: rgb{stepNum}.png\n",
    "   - /states/ - contains csv files of the format:\n",
    "      - endEffectorPt1X, endEffectorPt1Y, endEffectorPt2X, endEffectorPt2Y, endEffectorPt3X, endEffectorPt3Y, isOpen (boolean: {0 = closed, 1 = open})\n",
    "      - endEffectorX, endEffectorY, endEffectorZ, endEffectorRoll, endEffectorPitch, endEffectorYaw\n",
    "      - fileNames: states{stepNum}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VRNet import VRNet\n",
    "from VRNet import VRDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb mean:  tensor([0.0021, 0.0020, 0.0019])\n",
      "rgb std:  tensor([0.0007, 0.0008, 0.0010])\n",
      "depth mean:  tensor([0.0035])\n",
      "depth std:  tensor([0.0002])\n",
      "states mean:  tensor([-1.5721e-04, -1.5978e-03,  3.5809e-03,  2.7492e-04, -1.2118e-03,\n",
      "         4.2710e-04,  7.2372e-01], device='cuda:0')\n",
      "states std:  tensor([0.0205, 0.0240, 0.0485, 0.2719, 0.0424, 0.0585, 0.4478],\n",
      "       device='cuda:0')\n",
      "333 333 333\n"
     ]
    }
   ],
   "source": [
    "dataloader = VRDataLoader('data', 2, 5, batch_size=128)\n",
    "\n",
    "states = dataloader.states\n",
    "\n",
    "#set outliers to 0 (where |x| > 1)\n",
    "for i in range(len(states)):\n",
    "    if abs(states[i][0]) > 1:\n",
    "        #interpolate between two adjacent states\n",
    "        #if either value adjacent is out of bounds, use the other\n",
    "        if i == 0:\n",
    "            states[i][0] = states[i+1][0]\n",
    "        elif i == states.shape[0] - 1:\n",
    "            states[i][0] = states[i-1][0]\n",
    "        else:\n",
    "            states[i][0] = (states[i-1][0] + states[i+1][0]) / 2\n",
    "    if abs(states[i][1]) > 1:\n",
    "        if i == 0:\n",
    "            states[i][1] = states[i+1][1]\n",
    "        elif i == states.shape[0] - 1:\n",
    "            states[i][1] = states[i-1][1]\n",
    "        else:\n",
    "            states[i][1] = (states[i-1][1] + states[i+1][1]) / 2\n",
    "    if abs(states[i][2]) > 1:\n",
    "        if i == 0:\n",
    "            states[i][2] = states[i+1][2]\n",
    "        elif i == states.shape[0] - 1:\n",
    "            states[i][2] = states[i-1][2]\n",
    "        else:\n",
    "            states[i][2] = (states[i-1][2] + states[i+1][2]) / 2\n",
    "\n",
    "#apply a gaussian filter to smooth out the data\n",
    "gaussian_filter = np.array([1, 2, 3, 4, 5, 4, 3, 2, 1])\n",
    "gaussian_filter = gaussian_filter / np.sum(gaussian_filter)\n",
    "\n",
    "states = states.cpu().numpy()\n",
    "for i in range(6):\n",
    "    states[:, i] = np.convolve(states[:, i], gaussian_filter, mode='same')\n",
    "states = torch.tensor(states).to('cuda')\n",
    "\n",
    "# #plot x velocities\n",
    "# plt.plot([state[0].cpu() for state in states][0:500], 'bo')\n",
    "# plt.show()\n",
    "\n",
    "# #plot y velocities\n",
    "# plt.plot([state[1].cpu() for state in states][0:500], 'bo')\n",
    "# plt.show()\n",
    "\n",
    "# #plot z velocities\n",
    "# plt.plot([state[2].cpu() for state in states][0:500], 'bo')\n",
    "# plt.show()\n",
    "\n",
    "# #display image\n",
    "# plt.imshow(dataloader.rgb_images[0].permute(1,2,0))\n",
    "# plt.show()\n",
    "# #display histogram of image\n",
    "# plt.hist(dataloader.rgb_images[0].permute(1,2,0).flatten().cpu().numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1627,  0.2199, -0.0917,  0.5222,  0.1173, -0.0068,  1.0000],\n",
      "       device='cuda:0')\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#show a random img from the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "idx = 0 #random.randint(0, len(dataloader))\n",
    "data = dataloader[idx]\n",
    "rgb_img, depth_img, state = data[0][0], data[1][0], data[2][0]\n",
    "\n",
    "# plt.imshow(rgb_img.to('cpu').permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(depth_img.to('cpu').permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "print(state)\n",
    "\n",
    "print(len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add data augmentation\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomAffine(0, shear=3),\n",
    "    torchvision.transforms.RandomAffine(0, scale=(0.98, 1.02)),\n",
    "    # torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.05),\n",
    "    # torchvision.transforms.RandomApply([torchvision.transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))], p=0.5),\n",
    "])\n",
    "\n",
    "def applyTransforms(rgb_img, depth_img):\n",
    "    rngstate = torch.random.get_rng_state()\n",
    "    rgb_img = transform(rgb_img)\n",
    "    torch.random.set_rng_state(rngstate)\n",
    "    depth_img = transform(depth_img)\n",
    "    return rgb_img, depth_img\n",
    "\n",
    "idx = random.randint(0, len(dataloader))\n",
    "data = dataloader[idx]\n",
    "rgb_img, depth_img, state = data[0][1], data[1][1], data[2][1]\n",
    "\n",
    "rgb_img, depth_img = applyTransforms(rgb_img, depth_img)\n",
    "\n",
    "#apply same transform to both depth and rgb image\n",
    "# plt.imshow(rgb_img.permute(1, 2, 0))\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(depth_img.permute(1, 2, 0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the custom loss functions\n",
    "\n",
    "#create custom Lc loss function\n",
    "class LcLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LcLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss = torch.zeros(pred.shape[0])\n",
    "        for i in range(pred.shape[0]):\n",
    "            p = pred[i]\n",
    "            t = target[i]\n",
    "            loss[i] = torch.arccos(torch.dot(t, p) / (torch.norm(t) * torch.norm(p)))\n",
    "        \n",
    "        return torch.sum(loss)\n",
    "\n",
    "#create custom Lg loss function\n",
    "class LgLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LgLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss = torch.zeros(pred.shape[0])\n",
    "        for i in range(pred.shape[0]):\n",
    "            p = pred[i]\n",
    "            t = target[i]\n",
    "            loss[i] = p * torch.log(t) - (1 - p) * torch.log(1 - t)\n",
    "        return torch.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = [1, 0.01, 0.005, 0.0001]\n",
    "\n",
    "def train(model, data_loader, num_epochs, learning_rate, device):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    L1_loss = nn.L1Loss()\n",
    "    L2_loss = nn.MSELoss()\n",
    "    L_c_loss = LcLoss()\n",
    "    L_g_loss = nn.CrossEntropyLoss()\n",
    "    print(len(data_loader))\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(len(data_loader)):\n",
    "            rgb_img, depth_img, state = data_loader[i]\n",
    "            rgb_img = rgb_img\n",
    "            depth_img = depth_img\n",
    "\n",
    "            #get rgb and depth images\n",
    "            rgb_img = rgb_img.to(device).float()\n",
    "            depth_img = depth_img.to(device).float()\n",
    "\n",
    "            \n",
    "            #apply data augmentation\n",
    "            # rgb_img, depth_img = applyTransforms(rgb_img, depth_img)\n",
    "            \n",
    "            #add batch dimension\n",
    "            state = state.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(rgb_img, depth_img)\n",
    "            \n",
    "            #calculate combined loss\n",
    "            # loss = L1_loss(output[0:3], state[0:3]) * loss_weights[0]\n",
    "            #combine 0:3 and 6\n",
    "            important_output = torch.cat((output[:, 0:3], output[:, 6].unsqueeze(1)), dim=1)\n",
    "            important_state = torch.cat((state[:, 0:3], state[:, 6].unsqueeze(1)), dim=1)\n",
    "            \n",
    "            loss = L1_loss(important_output, important_state) # * loss_weights[1]\n",
    "            # loss += L_c_loss(output[:, 0:6], state[:, 0:6]) * loss_weights[2]\n",
    "            # loss += L_g_loss(output[:, 6], state[:, 6]) * loss_weights[3]\n",
    "            \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f'Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "device = torch.device('cuda')\n",
    "model = VRNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch: 0, Iteration: 0, Loss: 0.49408459663391113\n",
      "Epoch: 0, Iteration: 1, Loss: 0.5062539577484131\n",
      "Epoch: 1, Iteration: 0, Loss: 0.48429638147354126\n",
      "Epoch: 1, Iteration: 1, Loss: 0.5300107598304749\n",
      "Epoch: 2, Iteration: 0, Loss: 0.4693792760372162\n",
      "Epoch: 2, Iteration: 1, Loss: 0.47640857100486755\n",
      "Epoch: 3, Iteration: 0, Loss: 0.4860082268714905\n",
      "Epoch: 3, Iteration: 1, Loss: 0.4944054186344147\n",
      "Epoch: 4, Iteration: 0, Loss: 0.5602974891662598\n",
      "Epoch: 4, Iteration: 1, Loss: 0.49227261543273926\n",
      "Epoch: 5, Iteration: 0, Loss: 0.48775023221969604\n",
      "Epoch: 5, Iteration: 1, Loss: 0.46689027547836304\n",
      "Epoch: 6, Iteration: 0, Loss: 0.49689972400665283\n",
      "Epoch: 6, Iteration: 1, Loss: 0.47866714000701904\n",
      "Epoch: 7, Iteration: 0, Loss: 0.49108046293258667\n",
      "Epoch: 7, Iteration: 1, Loss: 0.5077520608901978\n",
      "Epoch: 8, Iteration: 0, Loss: 0.4396773874759674\n",
      "Epoch: 8, Iteration: 1, Loss: 0.47085100412368774\n",
      "Epoch: 9, Iteration: 0, Loss: 0.44369107484817505\n",
      "Epoch: 9, Iteration: 1, Loss: 0.4856809973716736\n",
      "Epoch: 10, Iteration: 0, Loss: 0.4891340732574463\n",
      "Epoch: 10, Iteration: 1, Loss: 0.4615185856819153\n",
      "Epoch: 11, Iteration: 0, Loss: 0.46232855319976807\n",
      "Epoch: 11, Iteration: 1, Loss: 0.4385075569152832\n",
      "Epoch: 12, Iteration: 0, Loss: 0.4078596830368042\n",
      "Epoch: 12, Iteration: 1, Loss: 0.4797189235687256\n",
      "Epoch: 13, Iteration: 0, Loss: 0.47232431173324585\n",
      "Epoch: 13, Iteration: 1, Loss: 0.46930086612701416\n",
      "Epoch: 14, Iteration: 0, Loss: 0.4444446563720703\n",
      "Epoch: 14, Iteration: 1, Loss: 0.443049818277359\n",
      "Epoch: 15, Iteration: 0, Loss: 0.4497402012348175\n",
      "Epoch: 15, Iteration: 1, Loss: 0.47101905941963196\n",
      "Epoch: 16, Iteration: 0, Loss: 0.4379391670227051\n",
      "Epoch: 16, Iteration: 1, Loss: 0.41072699427604675\n",
      "Epoch: 17, Iteration: 0, Loss: 0.3951505422592163\n",
      "Epoch: 17, Iteration: 1, Loss: 0.44466522336006165\n",
      "Epoch: 18, Iteration: 0, Loss: 0.4184362590312958\n",
      "Epoch: 18, Iteration: 1, Loss: 0.42910248041152954\n",
      "Epoch: 19, Iteration: 0, Loss: 0.41079723834991455\n",
      "Epoch: 19, Iteration: 1, Loss: 0.44958028197288513\n",
      "Epoch: 20, Iteration: 0, Loss: 0.38651618361473083\n",
      "Epoch: 20, Iteration: 1, Loss: 0.40310168266296387\n",
      "Epoch: 21, Iteration: 0, Loss: 0.4445797801017761\n",
      "Epoch: 21, Iteration: 1, Loss: 0.3950415253639221\n",
      "Epoch: 22, Iteration: 0, Loss: 0.4071699380874634\n",
      "Epoch: 22, Iteration: 1, Loss: 0.3890838623046875\n",
      "Epoch: 23, Iteration: 0, Loss: 0.37632811069488525\n",
      "Epoch: 23, Iteration: 1, Loss: 0.30845946073532104\n",
      "Epoch: 24, Iteration: 0, Loss: 0.3834986686706543\n",
      "Epoch: 24, Iteration: 1, Loss: 0.32420027256011963\n",
      "Epoch: 25, Iteration: 0, Loss: 0.3141682744026184\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16176/135923765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16176/1702785027.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, num_epochs, learning_rate, device)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, dataloader, 500, 0.0005, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 120, 160]) torch.Size([1, 1, 120, 160])\n",
      "output: 0.017391636967658997 0.024547874927520752 -0.0664740577340126 0.8793461322784424\n",
      "mse:  0.5588279\n",
      "tensor([-1.2353,  0.7866,  0.0091, -0.0331,  0.5424, -1.1276,  1.0000],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 3, 120, 160])\n",
      "tensor([-1.2353,  0.7866,  0.0091, -0.0331,  0.5424, -1.1276,  1.0000],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#test model on an example image\n",
    "import numpy as np\n",
    "import random\n",
    "idx = random.randint(0, len(dataloader))\n",
    "rgb_img, depth_img, state = dataloader[idx][0][0], dataloader[idx][1][0], dataloader[idx][2][0]\n",
    "\n",
    "model.eval()\n",
    "rgb_img = rgb_img.unsqueeze(0).to(device).float() \n",
    "depth_img = depth_img.unsqueeze(0).to(device).float()\n",
    "\n",
    "rgb_img = rgb_img.permute(0, 1, 2, 3)\n",
    "depth_img = depth_img.permute(0, 1, 2, 3)\n",
    "\n",
    "print(rgb_img.shape, depth_img.shape)\n",
    "output = model(rgb_img, depth_img)\n",
    "\n",
    "#show output (no scientific notation)\n",
    "print('output: {} {} {} {}'.format(output[0][0].item(), output[0][1].item(), output[0][2].item(), output[0][6].item(),))\n",
    "print('mse: ', np.mean((output.detach().cpu().numpy()[0:2] - state.detach().cpu().numpy())[0:2] ** 2))\n",
    "print(state)\n",
    "\n",
    "print(rgb_img.shape)\n",
    "# plt.imshow(rgb_img.permute(0, 2, 3, 1).cpu()[0])\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(rgb_img.permute(0, 2, 3, 1).cpu()[0])\n",
    "# plt.savefig(depth_img.permute(0, 2, 3, 1).cpu()[0])\n",
    "# plt.imshow(depth_img.permute(0, 2, 3, 1).cpu()[0])\n",
    "# plt.show()\n",
    "\n",
    "print(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model\n",
    "torch.save(model.state_dict(), 'new_model.pt')\n",
    "\n",
    "#load the model\n",
    "model = VRNet().to(device)\n",
    "model.load_state_dict(torch.load('new_model.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybullet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06b11139e13515c2711c878e587d72e1e158f858f2134781b554bf5f2a3bd4a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
